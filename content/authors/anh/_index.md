---
# Display name
title: Alejo J Nevado-Holgado 

# Is this the primary user of the site?
superuser: false

# Role/position
role: Associate Professor

# Organizations/Affiliations
organizations:
- name: Department of Psychiatry, University of Oxford
  url: "https://www.psych.ox.ac.uk/"

# Short bio (displayed in user profile at end of posts)
bio: I am an Associate Professor of the Department of Psychiatry and the Big Data Institute, and part of Dementia Research Oxford. I am very glad to supervise the AI team in the TNDR, formed by 10 excellent machine learners and bioinformaticians. Our focus is on the applications of machine learning and bioinformatics to mental health care. In addition, I also hold a position at the Big Data Institute, where we collaborate in the application of machine learning to genomics and target discovery. I am also consultant to a number of AI companies.


interests:
- NLP
- Genomics

# education:
#   courses:
#   - course: PhD 
#     institution: Stanford University
#     year: 2012
#   - course: MEng in Artificial Intelligence
#     institution: Massachusetts Institute of Technology
#     year: 2009
#   - course: BSc in Artificial Intelligence
#     institution: Massachusetts Institute of Technology
#     year: 2008

# Social/Academic Networking
# For available icons, see: https://sourcethemes.com/academic/docs/page-builder/#icons
#   For an email link, use "fas" icon pack, "envelope" icon, and a link in the
#   form "mailto:your-email@example.com" or "#contact" for contact widget.
social:
# - icon: envelope
#   icon_pack: fas
#   link: 'mailto:test@example.org'
- icon: twitter
  icon_pack: fab
  link: https://twitter.com/alejojnh
# - icon: google-scholar
#   icon_pack: ai
#   link: https://scholar.google.co.uk/citations?user=sIwtMXoAAAAJ
# - icon: github
#   icon_pack: fab
#   link: https://github.com/
- icon: home
  icon_pack: fas
  link: https://www.psych.ox.ac.uk/team/alejo-nevado-holgado


# Link to a PDF of your resume/CV from the About widget.
# To enable, copy your resume/CV to `static/files/cv.pdf` and uncomment the lines below.
# - icon: cv
#   icon_pack: ai
#   link: files/cv.pdf

# Enter email to display Gravatar (if Gravatar enabled in Config)
email: ""

# Highlight the author in author lists? (true/false)
highlight_name: false

# Organizational groups that you belong to (for People widget)
#   Set this to `[]` or comment out if you are not using People widget.
user_groups:
- Researchers
---
I am an Associate Professor of the Department of Psychiatry and the Big Data Institute, and part of Dementia Research Oxford. I am very glad to supervise the AI team in the TNDR, formed by 10 excellent machine learners and bioinformaticians. Our focus is on the applications of machine learning and bioinformatics to mental health care. In addition, I also hold a position at the Big Data Institute, where we collaborate in the application of machine learning to genomics and target discovery. I am also consultant to a number of AI companies.

The main technologies that we apply and develop in our laboratory are bioinformatics, artificial intelligence and high performance computing, and we apply these to data coming from biotech laboratories (i.e. genomics, transcriptomics, proteomics and metabolomics from human samples and iPSC cells) and hospitals or GP practices (i.e. Electronic Health Records and cohorts of volunteer patients). In the case of biotech data, bioinformatics methods allow us to know which are the metabolic processes associated with neurological diseases, such that appropriate pharmaceutical targets and drugs can be developed. In the case of hospital and GP data, artificial intelligence and neural networks allow us to extract from the text notes written by doctors what are the diagnoses, medications, symptoms and medical test results of millions of patients, which in turn can be analysed to evaluate the most efficient treatment per patient (personalised medicine), or whether certain drugs are serendipitously ameliorating psychiatric conditions (drug repurposing). Often, we combine biotech and hospital/GP data to validate laboratory results with real world evidence, such that any target or treatments we propose increases its chances of succeeding in the final stages of clinical trials. In all cases, high performance computing is the software (e.g. concurrent programming, threading or CUDA) and hardware (e.g. our 40 GPUs computational cluster) of choice to perform all these calculations in hours rather than years.

In summary, we believe in the benefits that information technologies can bring (and are bringing) to health care and drug discovery, and we actively work towards implementing these methods in the lab and the clinic, and on developing the very computational methods that make this possible.

I did my PhD in the University of Bristol, Department of Computer Science, under the supervision of Dr Rafal Bogacz and Dr John Terry. During these very interesting years, I used mathematical modelling, signal analysis, and machine learning to the study of the basal ganglia and Parkinsonâ€™s disease. With these techniques, we investigated which anomalies were generating the patterns of neuronal activity recorded by experimental groups, like our collaborator Dr Peter Magill and his team.

After some experimental training in Cambridge, now I am again applying machine learning and bioinformatics to the study of neurodegeneration, but this time to investigate biomarkers and the metabolic network in these diseases. It is known that Alzheimer's and Parkinson's disease have a very long prodromal course, which means that some underlying cause gradually destroys brain tissue, not being the condition diagnosed until 20 years later, when most of the brain is lost and unrecoverable. Therefore, any technique aiming at stopping the advance of these diseases needs first to be able to detect it in the prodromal stage. Traditional analysis approaches haven't been able to do so yet, although recent technological developments may change this luck.

For instance, a very large amount of medical and biological data has been produced during these decades of research, but this data is scattered across many institutes and hospitals, and its size makes it impossible to be analyzed by a person in a classical way. We are aiming at first linking all these data together, and then thoroughly analyzing it with machine learning and artificial intelligence approaches, which can make sense of data when it is beyond human interpretation due to size and complexity. We think this approach, which is proving of great success in the high-tech industry, has the best chances at detecting neurodegeneration in its prodromal stage and helping us understand how to modify its course and avoid brain damage.